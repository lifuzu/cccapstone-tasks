from __future__ import print_function

import sys
import signal

appName = "group1-2"

from pyspark import SparkContext, SparkConf
from pyspark.streaming import StreamingContext
from pyspark.streaming.kafka import KafkaUtils

def exit_gracefully(ssc):
    print("Gracefully stopping Spark Streaming Application")
    ssc.stop(True, True)
    print("Application stopped")
    sys.exit(0)
    
def updateFunc(new_values, last_sum):
    return sum(new_values) + (last_sum or 0)

def main(ssc):
    zkQuorum, topic = sys.argv[1:]
    kvs = KafkaUtils.createStream(ssc, zkQuorum, "spark-streaming-consumer", {topic: 1})
    lines = kvs.map(lambda x: x[1])
    data = lines.map(lambda line: line.split(",")) \
        .map(lambda word: (word[0], float(word[1])) ) \
        .aggregateByKey((0,0), lambda a,b: (a[0] + b, a[1] + 1), lambda a,b: (a[0] + b[0], a[1] + b[1])) \
        .mapValues(lambda v: v[0]/v[1]) \
        .updateStateByKey(updateFunc) \
        .transform(lambda rdd: rdd.sortBy(lambda (word, count): -count))
    data.pprint()

    ssc.start()
    ssc.awaitTermination()

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: kafka_group1_2.py <zk> <topic>", file=sys.stderr)
        exit(-1)

    conf = SparkConf().setAppName(appName).setMaster("yarn-cluster")
    sc = SparkContext(conf = conf)
    #sc = SparkContext(appName="PythonStreamingKafkaWordCount")
    ssc = StreamingContext(sc, 10)
    ssc.checkpoint("checkpoint")

    main(ssc)
    #try:
    #    main(ssc)
    #except KeyboardInterrupt:
    #    pass
    #finally:
    #    exit_gracefully(ssc)

